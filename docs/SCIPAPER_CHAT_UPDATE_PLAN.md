# SciPaper-Chat - Multi-Document RAG and Knowledge Base Integration Plan

## 1. Objective

This document outlines the plan to upgrade the `SciPaper-Chat` application from a single-document analysis tool to an advanced, multi-document research assistant. The updated system will accept a list of "seed" arXiv URLs, automatically expand this collection with similar papers from the `paperrec-index-endpoint` knowledge base, and allow for consolidated summarization and conversational Q&A across the entire corpus, with citations that attribute information to the specific source paper.

## 2. High-Level Workflow

The new user journey and system process will be as follows:

1.  **Input:** The user provides a list of 1-10 public arXiv URLs.
2.  **Corpus Expansion:** For each submitted URL, the system queries the `paperrec-search` similarity service to find the top 5 related papers. These results are collected and de-duplicated to form an expanded knowledge base for the session.
3.  **Full-Text Ingestion:** The system downloads the full PDF content for all papersâ€”both the user's initial set and the newly discovered similar papers. Each paper is then processed and ingested into the `scipaper_streaming_deployed` Vertex AI Vector Search index, using its arXiv ID as the unique `paper_id`.
4.  **Summarization:** A consolidated "running summary" is generated from the content of the initial papers provided by the user.
5.  **Multi-Document Q&A:** The user can ask questions, and the system will perform a vector search across the *entire* collection of ingested papers to find the most relevant context.
6.  **Source-Based Citation:** The final answer generated by the LLM will include citations that explicitly reference the arXiv ID of the source paper (e.g., `[from 2511.08191v1]`).

## 3. Core Architectural Changes

This upgrade requires two main architectural changes:

1.  **Introduction of an Orchestration Layer:** A new component (or logic integrated into the frontend) is needed to manage the multi-step workflow of corpus expansion and ingestion.
2.  **Modification of `SciPaper-Chat` for Multi-Document RAG:** The core `SciPaper-Chat` service must be modified to query across multiple `paper_id`s and to format prompts for source-based citations.

## 4. Detailed Implementation Steps

### Phase 1: Orchestration & Data Ingestion (New Component or Frontend Logic)

This phase manages the "setup" of the chat session by preparing the knowledge base.

1.  **Update UI for URL Input:**
    *   Modify the frontend (`frontend/demo.py` or another client) to accept a list of arXiv URLs instead of a single PDF file upload.

2.  **Implement Corpus Expansion Logic:**
    *   For each URL submitted by the user, make a `POST` request to the `paperrec-search` service's `/search` endpoint.
    *   Collect all the paper objects returned from these calls.
    *   Create a final, de-duplicated list of all papers for the session (user-submitted + similar papers).

3.  **Implement Full-Text Ingestion Loop:**
    *   For each paper in the final list:
        *   Use a robust HTTP client to download the PDF from the `link_pdf` URL provided in its metadata.
        *   Make a `POST` request to the existing `SciPaper-Chat` `/upload` endpoint. The request should pass the downloaded PDF content.
        *   **Crucially**, leverage the `ingest_pdf` function's optional `paper_id` parameter to explicitly set the paper's ID to its arXiv identifier (e.g., `2511.08191v1`). This will ensure citations are human-readable.
    *   The orchestrator must keep track of all arXiv IDs that are part of the session.

4.  **Generate Consolidated Summary:**
    *   After ingesting the initial 1-10 papers from the user, fetch their text chunks from Firestore (this may require a new helper function in `services/storage.py`).
    *   Combine the chunks and use the Gemini model to generate a "running summary" of the core papers.

### Phase 2: `SciPaper-Chat` Service Modifications (Code Changes Required)

This phase involves modifying the core RAG engine to support the new features.

1.  **API Layer (`models/api.py` and `main.py`):**
    *   **File:** `models/api.py`
    *   **Change:** Modify the `QueryRequest` Pydantic model. Rename `paper_id: str` to `paper_ids: list[str]`.
    *   **File:** `main.py`
    *   **Change:** Update the `/query` endpoint to accept the modified `QueryRequest` and pass the `paper_ids` list to the agent.

2.  **Agent Layer (`agents/adk_agent.py`):**
    *   **Change `answer_question`:** Update its signature to accept `paper_ids: list[str]` instead of `paper_id: str`.
    *   **Change `_search`:**
        *   Update its signature to accept `paper_ids: list[str]`.
        *   Modify its return value. Instead of returning a list of text strings, it should return a list of chunk dictionaries (`List[Dict[str, str]]`) retrieved from `storage.fetch_chunks`. This ensures the `paper_id` for each chunk is preserved.
    *   **Change `build_prompt`:**
        *   Update its signature to accept `contexts: List[Dict[str, str]]`.
        *   Modify the logic to construct the `context_block`. Each chunk's text should be prepended with an identifier, like `--- CONTEXT from paper {chunk['paper_id']} ---`.
        *   Update the main prompt instructions to require citations in the new format: `[from <paper_id>]`.

3.  **Service Layer (`services/vector_search.py`):**
    *   **Change `query`:**
        *   Update its signature to accept `paper_ids: list[str]`.
        *   Modify the filter creation logic. The `Namespace` filter for Vertex AI Vector Search supports a list of tokens. The code should be changed from `allow_tokens=[paper_id]` to `allow_tokens=paper_ids`.

## 5. Summary of Required Code Changes

-   **`SciPaper-Chat/models/api.py`**:
    -   [ ] Update `QueryRequest` to use `paper_ids: list[str]`.
-   **`SciPaper-Chat/main.py`**:
    -   [ ] Update `/query` endpoint to handle the new `QueryRequest` model.
-   **`SciPaper-Chat/agents/adk_agent.py`**:
    -   [ ] Modify `answer_question` to accept a list of paper IDs.
    -   [ ] Modify `_search` to pass the list of IDs to the vector search service and to return full chunk metadata.
    -   [ ] Modify `build_prompt` to format the context with source IDs and to include the new citation instructions.
-   **`SciPaper-Chat/services/vector_search.py`**:
    -   [ ] Update `query` to accept a list of paper IDs and apply them as a filter.
-   **`SciPaper-Chat/frontend/` (or new Orchestrator Component)**:
    -   [ ] Implement the new UI for URL submission.
    -   [ ] Add the orchestration logic for corpus expansion and ingestion.
    -   [ ] Manage the list of session `paper_ids` to be sent with each query.
